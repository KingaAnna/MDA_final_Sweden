{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8464bac3",
   "metadata": {},
   "source": [
    "# (Attempt at) Visualizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1751bcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary packages\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "\n",
    "# Take all data into account or just 2020 data (for speed)\n",
    "USE_ALL_DATA = True\n",
    "\n",
    "# Read in the data.\n",
    "if USE_ALL_DATA:\n",
    "    df1 = pd.read_csv(\"RawData/us-counties-2020.csv\", dtype={\"fips\" : str})\n",
    "    df2 = pd.read_csv(\"RawData/us-counties-2021.csv\", dtype={\"fips\" : str})\n",
    "    df3 = pd.read_csv(\"RawData/us-counties-2022.csv\", dtype={\"fips\" : str})\n",
    "    df = pd.concat([df1, df2, df3], ignore_index = True)\n",
    "else:\n",
    "    df = pd.read_csv(\"RawData/us-counties-2020.csv\", dtype={\"fips\" : str})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6d62e9",
   "metadata": {},
   "source": [
    "### Template from internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef87640f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "with urlopen('https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json') as response:\n",
    "    counties = json.load(response)\n",
    "\n",
    "df_temp = pd.read_csv(\"https://raw.githubusercontent.com/plotly/datasets/master/fips-unemp-16.csv\",\n",
    "                   dtype={\"fips\": str})\n",
    "\n",
    "fig = px.choropleth(df_temp, geojson=counties, locations='fips', color='unemp',\n",
    "                           color_continuous_scale=\"Viridis\",\n",
    "                           range_color=(0, 12),\n",
    "                           scope=\"usa\",\n",
    "                           labels={'unemp':'unemployment rate'}\n",
    "                          )\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "fig.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b88635",
   "metadata": {},
   "source": [
    "### Aggregate all data per county and plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9dddf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are all observations for the USA?\n",
    "print(\"All observations are from the USA (geoid starts with 'USA-'):\", \\\n",
    "      all(df.apply(lambda row: row['geoid'].startswith(\"USA-\"), axis = 1)))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ae56cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a column containing fips and select only necessary columns\n",
    "df['fips'] = df.apply(lambda row: row['geoid'][4:], axis = 1)\n",
    "df = df[['date', 'fips', 'cases']]\n",
    "\n",
    "# Aggregate cases per county\n",
    "aggregate_data = df.groupby(\"fips\", as_index = False).agg({\"cases\" : \"sum\"})\n",
    "\n",
    "# Scale counts based on population\n",
    "pop_df = pd.read_csv(\"RawData/county_complete.csv\", dtype={'fips':str})\n",
    "pop_df = pop_df[['fips', 'pop_2019']]\n",
    "\n",
    "# Merge both data sets. Performing this inner merge apparenty loses a lot of observations. From the map below, we see that\n",
    "# data for some states are missing, like f.e. California.\n",
    "# --> Check other data set\n",
    "inner_merge = pd.merge(left = aggregate_data, right = pop_df, left_on = 'fips', right_on = 'fips')\n",
    "\n",
    "print(aggregate_data.shape)\n",
    "print(inner_merge.shape)\n",
    "\n",
    "# Compute cases/population.\n",
    "merged = inner_merge.assign(cpp = lambda row: row['cases']/row['pop_2019'])\n",
    "\n",
    "print()\n",
    "print(merged.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063027ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the county data in a map\n",
    "\n",
    "with urlopen('https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json') as response:\n",
    "    counties = json.load(response)\n",
    "\n",
    "fig = px.choropleth(merged, geojson=counties, locations='fips', color='cpp',\n",
    "                           color_continuous_scale=\"Viridis\",\n",
    "                           range_color=(0, 0.30),\n",
    "                           scope=\"usa\",\n",
    "                           labels={'cpp':'cases of covid per population'}\n",
    "                          )\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9527b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate some more.\n",
    "\n",
    "# Get all observations that have a fips code from California\n",
    "pop_df = pd.read_csv(\"RawData/county_complete.csv\", dtype={'fips':str})\n",
    "pop_df = pop_df[['fips', 'pop_2019']]\n",
    "pop_df['Cali'] = pop_df.apply(lambda row: row['fips'].startswith('06'), axis = 1)\n",
    "pop_df.loc[pop_df['Cali'] == True]\n",
    "\n",
    "# --> The data set just has no information about California"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7ee622",
   "metadata": {},
   "source": [
    "### Let's use a different data set to get population per county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbab66d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data set\n",
    "pop_df2 = pd.read_csv(\"RawData/County_Pop.csv\", dtype={'GEOID': str})\n",
    "pop_df2 = pop_df2[['GEOID', 'NAME', 'County Pop_POPESTIMATE2020']]\n",
    "pop_df2 = pop_df2.rename(columns = {'GEOID': 'fips', 'NAME': 'county', 'County Pop_POPESTIMATE2020': 'Pop2020'})\n",
    "\n",
    "# Merge data sets \n",
    "inner_merge2 = pd.merge(left = aggregate_data, right = pop_df2, left_on = 'fips', right_on = 'fips')\n",
    "\n",
    "print(aggregate_data.shape)\n",
    "print(inner_merge2.shape)\n",
    "\n",
    "# Compute cases/population.\n",
    "merged2 = inner_merge2.assign(cpp = lambda row: row['cases']/row['Pop2020'])\n",
    "\n",
    "print()\n",
    "print(merged2[['cases', 'Pop2020', 'cpp']].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113c2e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the county data in a map\n",
    "\n",
    "with urlopen('https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json') as response:\n",
    "    counties = json.load(response)\n",
    "\n",
    "fig = px.choropleth(merged2, geojson=counties, locations='fips', color='cpp',\n",
    "                           color_continuous_scale=\"Viridis\",\n",
    "                           range_color=(0, 0.30),\n",
    "                           scope=\"usa\",\n",
    "                           labels={'cpp':'cases of covid per population'}\n",
    "                          )\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04ba042",
   "metadata": {},
   "source": [
    "## Plot data per week with a cool slider\n",
    "\n",
    "Be aware: the last cell is quite slow code. Even though it is a slider, I would not recommend sliding the dot around, but just clicking on the spot where you want the slider to be. I would also not recommend sliding this slider around a lot, just for fun (not that I did that...) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1ea1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some more packages\n",
    "import ipywidgets as widgets\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40300728",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aggregate data per week (again on county level)\n",
    "\n",
    "# Running time: ~2-3 mins\n",
    "\n",
    "# Convert 'date' column to a more workable format\n",
    "if type(df.loc[0, 'date']) == str:\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Extract the weeks\n",
    "# NOTE: if this code is used on all data, this needs to be adapted to also include 'year' information. Otherwise,\n",
    "#       data from f.e. '10/01/2020' and '10/01/2021' will be aggregated together.\n",
    "\n",
    "# Use Monday of the week of the first recorded date as reference\n",
    "first_date = min(df['date'])\n",
    "REFERENCE_DATE = first_date - dt.timedelta(days=first_date.weekday())\n",
    "\n",
    "def get_week_number(row, REFERENCE_DATE):\n",
    "    DAYS_IN_WEEK = 7\n",
    "    t = row['date'] - REFERENCE_DATE\n",
    "    start_of_week = row['date'] - dt.timedelta(days=row['date'].weekday())\n",
    "    end_of_week = start_of_week + dt.timedelta(days=6)\n",
    "    return (t.days // DAYS_IN_WEEK, start_of_week, end_of_week)\n",
    "\n",
    "df[['week', 'startOfWeek', 'endOfWeek']] = \\\n",
    "    df.apply(lambda row: get_week_number(row, REFERENCE_DATE), axis = 1, result_type=\"expand\")\n",
    "\n",
    "# Aggregate data by weeks and fips\n",
    "agg_week = df.groupby(['week', 'fips'], as_index = False).agg({\"cases\" : \"sum\", \"startOfWeek\" : \"max\", \"endOfWeek\" : \"max\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefc1152",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge data week data with population data\n",
    "\n",
    "# Since it turned out that also the \"co-est2021-alldata.csv\" sometimes contained wrong information (leading to results that\n",
    "# in one week 90% of the county population got infected, which is obviously non-sensical), we use yet another data set to get\n",
    "# the population per county.\n",
    "\n",
    "population = pd.read_csv(\"RawData/County_Pop.csv\")\n",
    "population = population[['GEOID', 'NAME', 'County Pop_POPESTIMATE2020']]\n",
    "population = population.rename(columns = {'GEOID': 'fips', 'NAME': 'county', 'County Pop_POPESTIMATE2020': 'Pop2020'})\n",
    "population['fips'] = population['fips'].apply('{:0>5}'.format)\n",
    "population = population.sort_values('fips', ascending=True)\n",
    "\n",
    "week_merge = pd.merge(left = agg_week, right = population, left_on = 'fips', right_on = 'fips').dropna()\n",
    "\n",
    "print(agg_week.shape)\n",
    "print(week_merge.shape)\n",
    "\n",
    "# Compute cases/population.\n",
    "week_merge['casespercapita'] = 100*week_merge['cases']/week_merge['Pop2020']\n",
    "\n",
    "print()\n",
    "print(week_merge[['cases', 'Pop2020', 'casespercapita']].describe())\n",
    "\n",
    "# Only retain necessary columns\n",
    "week_merge = week_merge[['fips', 'week', 'casespercapita', 'startOfWeek', 'endOfWeek']]\n",
    "week_merge.to_csv(\"PreprocessedData/week_merge.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c0228c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = widgets.IntSlider(\n",
    "    description='a',\n",
    "    value=7,\n",
    "    min=0,\n",
    "    max=max(week_merge['week']),\n",
    "    step=1)\n",
    "\n",
    "with urlopen('https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json') as response:\n",
    "        counties = json.load(response)\n",
    "\n",
    "def f(a):\n",
    "    # Plot the county data in a map\n",
    "    fig = px.choropleth(week_merge[week_merge['week'] == a], geojson=counties, locations='fips', color='casespercapita',\n",
    "                               color_continuous_scale=\"Viridis\",\n",
    "                               range_color=(0, 0.5),\n",
    "                               scope=\"usa\",\n",
    "                               labels={'casespercapita':'%new cases <br> (on county level)'}\n",
    "                              )    \n",
    "    fig.update_layout(title_text = \"Covid-19 cases for week \" + str(a) + '<br>' + \\\n",
    "                     \"(\" + week_merge.loc[a, 'startOfWeek'].strftime(\"%d/%b/%Y\") + \" - \" + \\\n",
    "                      week_merge.loc[a, 'endOfWeek'].strftime(\"%d/%b/%Y\") + \")\",\n",
    "                     margin={\"r\":0,\"t\":50,\"l\":0,\"b\":0, \"autoexpand\" : True},\n",
    "                     width = 800)\n",
    "    fig.show()\n",
    "\n",
    "out = widgets.interactive_output(f, {'a': a})\n",
    "\n",
    "widgets.HBox([widgets.VBox([a]), out])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba955ce3",
   "metadata": {},
   "source": [
    "## Pre-compute all the images and make a video of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910fba12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Even more imports\n",
    "import io\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994b1c87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# kaleido needs to be pip-installed\n",
    "\n",
    "# Running time: long\n",
    "\n",
    "with urlopen('https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json') as response:\n",
    "        counties = json.load(response)\n",
    "\n",
    "def f(a, MAX_WEEK):\n",
    "    print(\"Busy making plot for week {}. ({}% completion)\".format(a, round(100*(a / MAX_WEEK), 1)))\n",
    "    \n",
    "    # Plot the county data in a map\n",
    "    fig = px.choropleth(week_merge[week_merge['week'] == a], geojson=counties, locations='fips', color='cpp',\n",
    "                               color_continuous_scale=\"Viridis\",\n",
    "                               range_color=(0, 0.5),\n",
    "                               scope=\"usa\",\n",
    "                               labels={'cpp':'%new cases <br> (on county level)'}\n",
    "                              )    \n",
    "    fig.update_layout(title_text = \"Covid-19 cases for week \" + str(a) + '<br>' + \\\n",
    "                     \"(\" + week_merge.loc[a, 'startOfWeek'].strftime(\"%d/%b/%Y\") + \" - \" + \\\n",
    "                      week_merge.loc[a, 'endOfWeek'].strftime(\"%d/%b/%Y\") + \")\",\n",
    "                     margin={\"r\":0,\"t\":50,\"l\":0,\"b\":0, \"autoexpand\" : True},\n",
    "                     width = 800)\n",
    "    \n",
    "    name = \"C:/Users/wille/OneDrive/Documenten/,School/Master/Modern Data Analytics/Project/FiguresVisualization/\" + \\\n",
    "        str(a) + \".png\"\n",
    "    \n",
    "    fig.write_image(name)    \n",
    "\n",
    "for a in range(min(week_merge['week']), max(week_merge['week']) + 1):\n",
    "    f(a, max(week_merge['week']))\n",
    "\n",
    "# ToDo?: Implement a progress bar widget\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c586c97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
