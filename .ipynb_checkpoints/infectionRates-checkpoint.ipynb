{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed54e913",
   "metadata": {},
   "source": [
    "# Infection Rates\n",
    "\n",
    "What to do?\n",
    "* Get the weekly percentage of infections on a county level --> Already done in Visualization.ipynb\n",
    "* Assuming people are infectious for 7 days, it is easy to compute the infection number for each week as $r = \\frac{\\#cases\\_week\\_i+1}{\\#cases\\_week\\_i}$. This number represents the average amount of people each Covid patient infects in that week\n",
    "\n",
    "Then...\n",
    "* Compare a graph/heatmap of r with covid measures taken (perhaps on state level)\n",
    "* Perhaps we can cluster based on this r?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7942a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary packages\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "import ipywidgets as widgets\n",
    "import datetime as dt\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "# Take all data into account or just 2020 data (for speed)\n",
    "USE_ALL_DATA = True\n",
    "\n",
    "# Read in the data.\n",
    "if USE_ALL_DATA:\n",
    "    df1 = pd.read_csv(\"RawData/us-counties-2020.csv\", dtype={\"fips\" : str})\n",
    "    df2 = pd.read_csv(\"RawData/us-counties-2021.csv\", dtype={\"fips\" : str})\n",
    "    df3 = pd.read_csv(\"RawData/us-counties-2022.csv\", dtype={\"fips\" : str})\n",
    "    df = pd.concat([df1, df2, df3], ignore_index = True)\n",
    "else:\n",
    "    df = pd.read_csv(\"RawData/us-counties-2020.csv\", dtype={\"fips\" : str})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485886e8",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "Getting the weekly percentages of infections on county level was already done in Visualization.ipynb, so I copied the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaf14b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a column containing fips and select only necessary columns\n",
    "df[['fips', 'state']] = df.apply(lambda row: (row['geoid'][4:], row['geoid'][4:6]), axis = 1, result_type=\"expand\")\n",
    "df = df[['date', 'fips', 'cases', 'state']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b035d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aggregate data per week (both on county level)\n",
    "\n",
    "# Running time: ~2-3 mins\n",
    "\n",
    "# Convert 'date' column to a more workable format\n",
    "if type(df.loc[0, 'date']) == str:\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Extract the weeks\n",
    "# NOTE: if this code is used on all data, this needs to be adapted to also include 'year' information. Otherwise,\n",
    "#       data from f.e. '10/01/2020' and '10/01/2021' will be aggregated together.\n",
    "\n",
    "# Use Monday of the week of the first recorded date as reference\n",
    "first_date = min(df['date'])\n",
    "REFERENCE_DATE = first_date - dt.timedelta(days=first_date.weekday())\n",
    "\n",
    "def get_week_number(row, REFERENCE_DATE):\n",
    "    DAYS_IN_WEEK = 7\n",
    "    t = row['date'] - REFERENCE_DATE\n",
    "    start_of_week = row['date'] - dt.timedelta(days=row['date'].weekday())\n",
    "    end_of_week = start_of_week + dt.timedelta(days=6)\n",
    "    return (t.days // DAYS_IN_WEEK, start_of_week, end_of_week)\n",
    "\n",
    "df[['week', 'startOfWeek', 'endOfWeek']] = \\\n",
    "    df.apply(lambda row: get_week_number(row, REFERENCE_DATE), axis = 1, result_type=\"expand\")\n",
    "\n",
    "# Aggregate data by weeks and fips \n",
    "agg_week_county = df.groupby(['week', 'fips'], as_index = False).agg({\"cases\" : \"sum\", \"startOfWeek\" : \"min\", \"endOfWeek\" : \"max\"})\n",
    "\n",
    "# Aggregate data by weeks and state\n",
    "agg_week_state = df.groupby(['week', 'state'], as_index = False).agg({\"cases\" : \"sum\", \"startOfWeek\" : \"min\", \"endOfWeek\" : \"max\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528c1c46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For each state and for each week, compute the infection number. We could also do the same on a county level,\n",
    "# but this takes a lot of time so we don't.\n",
    "\n",
    "def get_infection_number(row, all_data):\n",
    "    cases = row['cases']\n",
    "    week = row['week']\n",
    "    state = row['state']\n",
    "    \n",
    "    next_week_cases = all_data.loc[(all_data['week'] == week + 1) & (all_data['state'] == state)]\n",
    "    \n",
    "    # For debugging\n",
    "    \"\"\"\n",
    "    if row['state'] == \"04\":\n",
    "        print(\"Analizing week\", row['week'])\n",
    "        print(\"cases\")\n",
    "        print(cases)\n",
    "        print(\"\")\n",
    "        print(\"next week cases\")\n",
    "        print(int(next_week_cases['cases']))\n",
    "        print(\"\")\n",
    "    \"\"\"\n",
    "    \n",
    "    if (next_week_cases.shape[0] >= 1) & (cases > 0):\n",
    "        return int(next_week_cases['cases']) / cases\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "agg_week_state['r'] = agg_week_state.apply(lambda row: get_infection_number(row, agg_week_state), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b66e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save agg_week_state for the app and possibly other purposes\n",
    "agg_week_state.to_csv(\"PreprocessedData/agg_week_state.csv\")\n",
    "\n",
    "agg_week_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26acd9e0",
   "metadata": {},
   "source": [
    "## Compare evolution of r with Covid measures taken (on state level)\n",
    "\n",
    "The values of the infection number seem to oscillate a lot. Maybe this is because states only reported the infections bi/tri-weekly? Therefore, also a smoothing curve is fitted to the plots. Perhaps it would be smart to work with the smoothed values as opposed to the actual values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b563a535",
   "metadata": {},
   "source": [
    "### Pick a state (f.e. California) and plot the infection numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b985f2f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "California = agg_week_state.loc[agg_week_state['state'] == \"06\"]\n",
    "California.plot(x = 'week', y = 'r')\n",
    "\n",
    "yhat = savgol_filter(California['r'], 41, 3)\n",
    "plt.pyplot.plot(California['week'],yhat, color='red')\n",
    "plt.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f714fb2",
   "metadata": {},
   "source": [
    "### Pick the first 40 states and plot them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f13065c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NBR_COLS = 4\n",
    "NBR_ROWS = 10\n",
    "\n",
    "fig, axs = plt.pyplot.subplots(NBR_ROWS, NBR_COLS)\n",
    "\n",
    "fig.set_figheight(4*NBR_ROWS)\n",
    "fig.set_figwidth(4*NBR_COLS)\n",
    "\n",
    "for i in range(0, NBR_ROWS):\n",
    "    for j in range(0, NBR_COLS):\n",
    "        state_nbr = (i)*3 + j + 1\n",
    "        if state_nbr < 10:\n",
    "            state_nbr = \"0\" + str(state_nbr)\n",
    "        else:\n",
    "            state_nbr = str(state_nbr)\n",
    "\n",
    "        State = agg_week_state.loc[agg_week_state['state'] == state_nbr]\n",
    "        axs[i,j].plot(State['week'], State['r'])\n",
    "        # State.plot(x = 'week', y = 'r')\n",
    "\n",
    "        if State['r'].shape[0] > 21:\n",
    "            yhat = savgol_filter(State['r'], 21, 3)\n",
    "            axs[i,j].plot(State['week'],yhat, color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f92668",
   "metadata": {},
   "source": [
    "## Overlay these plots with information of Covid measures taken\n",
    "\n",
    "Displaying the measures taken in terms of closing schools and mask obligation is kind of interesting when comparing them to the smoothing curve.\n",
    "\n",
    "Legend for the colours:\n",
    "* Vaccination\n",
    "    * Red = Vaccination available for all people at risk (elderly, front-line workers, etc.)\n",
    "    * Green = Vaccination no longer available for all these people (likely because they all got vaccinated)\n",
    "* Masks\n",
    "    * Orange = Masks obligatory in all public spaces where social distancing is not possible\n",
    "    * Blue = Opposite of orange\n",
    "* Schools\n",
    "    * Brown = At least some types of schools need to close\n",
    "    * Yellow = No such restrictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5774d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "measures = pd.read_csv(\"PreprocessedData/covidMeasures.csv\")\n",
    "\n",
    "# Drop first row (doesn't indicate any changes)\n",
    "measures = measures.loc[1:,]\n",
    "measures.reset_index(inplace = True, drop = True)\n",
    "\n",
    "# Get week number of measures taken (REFERENCE_DATE is initialized above)\n",
    "def get_week_measures(row, REFERENCE_DATE):\n",
    "    DAYS_IN_WEEK = 7\n",
    "    date = dt.datetime.strptime(row['Date'], \"%Y-%m-%d\")\n",
    "    \n",
    "    t = date - REFERENCE_DATE\n",
    "    return (t.days // DAYS_IN_WEEK)\n",
    "\n",
    "measures['week'] = measures.apply(lambda row: get_week_measures(row, REFERENCE_DATE), axis = 1)\n",
    "\n",
    "measures.to_csv(\"PreprocessedData/measures.csv\")\n",
    "measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d8cfd1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DISPLAY_VACCINATION = True\n",
    "DISPLAY_MASKS = False\n",
    "DISPLAY_SCHOOLS = False\n",
    "\n",
    "NBR_COLS = 4\n",
    "NBR_ROWS = 10\n",
    "\n",
    "fig, axs = plt.pyplot.subplots(NBR_ROWS, NBR_COLS)\n",
    "\n",
    "fig.set_figheight(4*NBR_ROWS)\n",
    "fig.set_figwidth(4*NBR_COLS)\n",
    "\n",
    "for i in range(0, NBR_ROWS):\n",
    "    for j in range(0, NBR_COLS):\n",
    "        state_nbr_int = (i)*3 + j + 1\n",
    "        if state_nbr_int < 10:\n",
    "            state_nbr = \"0\" + str(state_nbr_int)\n",
    "        else:\n",
    "            state_nbr = str(state_nbr_int)\n",
    "\n",
    "        State = agg_week_state.loc[agg_week_state['state'] == state_nbr]\n",
    "        axs[i,j].plot(State['week'], State['r'])\n",
    "        # State.plot(x = 'week', y = 'r')\n",
    "\n",
    "        if State['r'].shape[0] > 21:\n",
    "            yhat = savgol_filter(State['r'], 21, 3)\n",
    "            axs[i,j].plot(State['week'],yhat, color='red')\n",
    "        \n",
    "        # Display Vaccination data\n",
    "        if DISPLAY_VACCINATION:\n",
    "            state_measures = measures.loc[measures['fips'] == state_nbr_int, ['week', 'Vaccination']]\n",
    "            state_measures = state_measures.loc[state_measures['Vaccination'].shift() != state_measures['Vaccination']]\n",
    "            state_measures.reset_index(inplace = True, drop = True)\n",
    "            state_measures = state_measures.loc[1:,]\n",
    "            state_measures.reset_index(inplace = True, drop = True)\n",
    "            \n",
    "            for change in range(state_measures.shape[0]):\n",
    "                week = state_measures.loc[change, 'week']\n",
    "                c = 'r' if state_measures.loc[change, 'Vaccination'] == 1 else 'g'\n",
    "                axs[i,j].axvline(x = week, color = c, linestyle = '--')\n",
    "        \n",
    "        # Display Vaccination data\n",
    "        if DISPLAY_MASKS:\n",
    "            state_measures = measures.loc[measures['fips'] == state_nbr_int, ['week', 'Masks']]\n",
    "            state_measures = state_measures.loc[state_measures['Masks'].shift() != state_measures['Masks']]\n",
    "            state_measures.reset_index(inplace = True, drop = True)\n",
    "            state_measures = state_measures.loc[1:,]\n",
    "            state_measures.reset_index(inplace = True, drop = True)\n",
    "            \n",
    "            for change in range(state_measures.shape[0]):\n",
    "                week = state_measures.loc[change, 'week']\n",
    "                c = 'orange' if state_measures.loc[change, 'Masks'] == 1 else 'b'\n",
    "                axs[i,j].axvline(x = week, color = c, linestyle = '--')\n",
    "        \n",
    "        # Display Vaccination data\n",
    "        if DISPLAY_SCHOOLS:\n",
    "            state_measures = measures.loc[measures['fips'] == state_nbr_int, ['week', 'Close_schools']]\n",
    "            state_measures = state_measures.loc[state_measures['Close_schools'].shift() != state_measures['Close_schools']]\n",
    "            state_measures.reset_index(inplace = True, drop = True)\n",
    "            state_measures = state_measures.loc[1:,]\n",
    "            state_measures.reset_index(inplace = True, drop = True)\n",
    "            \n",
    "            for change in range(state_measures.shape[0]):\n",
    "                week = state_measures.loc[change, 'week']\n",
    "                c = 'brown' if state_measures.loc[change, 'Close_schools'] == 1 else 'y'\n",
    "                axs[i,j].axvline(x = week, color = c, linestyle = '--')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc94229",
   "metadata": {},
   "source": [
    "## Use SVM to predict these smoothed curves\n",
    "\n",
    "This section is based on the code found here:\n",
    "https://github.com/microsoft/ML-For-Beginners/blob/main/7-TimeSeries/3-SVR/README.md?fbclid=IwAR3pwIAcAwMk6gY1vNfvXQ9Xi2QXBwnrw_iDMcgBcbRElvs1qfRkFAvf878"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03edd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab99f45",
   "metadata": {},
   "source": [
    "### First, try it out on only one state (California)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a2e909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select California data and plot it\n",
    "state = agg_week_state.loc[agg_week_state['state'] == '06']\n",
    "\n",
    "fig = make_subplots(rows=1, cols=1)\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=state['week'], y=state['r'], name=\"Infection rates\"),\n",
    "    row=1, col=1)\n",
    "\n",
    "if state['r'].shape[0] > 21:\n",
    "    state['yhat'] = savgol_filter(state['r'], 21, 3)\n",
    "    fig.add_trace(go.Scatter(x=state['week'], y=state['yhat'], name=\"Smoothed data\"),\n",
    "                  row=1, col=1)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b820ab",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "\n",
    "Before we can apply an SVM to do time series predictions, we first need to reformat the data to the required format for applying a SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf78ca2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We divide the data into a training and test set. Specify the number of weeks you want the trainset to contain below\n",
    "test_start_week = 90\n",
    "\n",
    "train = state.copy()[state.week < test_start_week][['yhat']]\n",
    "test = state.copy()[state.week >= test_start_week][['yhat']]\n",
    "\n",
    "print('Training data shape: ', train.shape)\n",
    "print('Test data shape: ', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03c77e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting to numpy arrays\n",
    "train_data = train.values\n",
    "test_data = test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e8452c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a time step. This is equal to 1 + lag of predictions.\n",
    "# THIS VALUE SHOULD BE TUNED LATER\n",
    "timesteps=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c67442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat the training data with the selected timesteps. Each row in train_data_timesteps contains a sequence of observations\n",
    "# of length 'timesteps'\n",
    "train_data_timesteps=np.array([[j for j in train_data[i:i+timesteps]] for i in range(0,len(train_data)-timesteps+1)])[:,:,0]\n",
    "train_data_timesteps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d75a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same for test data\n",
    "test_data_timesteps=np.array([[j for j in test_data[i:i+timesteps]] for i in range(0,len(test_data)-timesteps+1)])[:,:,0]\n",
    "test_data_timesteps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebf3883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The last observation of each time series will become the response, which we will try to predict based on all the previous\n",
    "# observations in that timestep\n",
    "x_train, y_train = train_data_timesteps[:,:timesteps-1], train_data_timesteps[:,timesteps-1]\n",
    "x_test, y_test = test_data_timesteps[:,:timesteps-1], test_data_timesteps[:,timesteps-1]\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d842856",
   "metadata": {},
   "source": [
    "### Apply a support vector machine regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255decd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the model\n",
    "# THESE HYPERPARAMETERS SHOULD BE TUNED!\n",
    "# Gamma = s.d. of radial basis function (i.e. sigma)\n",
    "# c = regularization parameter\n",
    "# epsilon = epsilon of the Vapnik eps-insensitive loss function\n",
    "model = SVR(kernel='rbf',gamma=0.5, C=10, epsilon = 0.05)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = model.predict(x_train).reshape(-1,1)\n",
    "y_test_pred = model.predict(x_test).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcfed0e",
   "metadata": {},
   "source": [
    "### Assess the performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b746e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the MSE\n",
    "n = len(y_test_pred)\n",
    "mse = sum([(y_test_pred[i] - y_test[i])**2 for i in range(len(y_test_pred))])\n",
    "print(\"The mse for this model is {}\".format(round(mse[0], 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860dd0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the predicted versus actual values\n",
    "train = state.copy()[state.week <= test_start_week][['yhat']]\n",
    "test = state.copy()[state.week >= test_start_week][['yhat']]\n",
    "\n",
    "weeks_training = state.loc[state['week'] <= test_start_week, 'week']\n",
    "weeks_testing  = state.loc[state['week'] >= test_start_week, 'week']\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=weeks_training, y=train['yhat'], name=\"Training data\", connectgaps=True))\n",
    "fig.add_trace(go.Scatter(x=weeks_testing, y=test['yhat'], name=\"Test data\", connectgaps=True))\n",
    "fig.add_trace(go.Scatter(x=weeks_testing.iloc[timesteps:], y=y_test_pred.flatten(), name=\"Predicted data\", connectgaps=True))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dbe1bd",
   "metadata": {},
   "source": [
    "## Now implementing a pipeline that allows us to tune hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1a530e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_start_week = 90\n",
    "timesteps=5\n",
    "\n",
    "# Define the pipeline. Note that this pipeline does not include the information about the lag\n",
    "pipe = Pipeline([('regressor', SVR(kernel='rbf', gamma=0.5, C = 10, epsilon = 0.05))])\n",
    "\n",
    "# Reformat data\n",
    "state = agg_week_state.loc[agg_week_state['state'] == '06']\n",
    "\n",
    "if state['r'].shape[0] > 21:\n",
    "    state['yhat'] = savgol_filter(state['r'], 21, 3)\n",
    "\n",
    "train = state.copy()[state.week < test_start_week][['week', 'yhat']]\n",
    "test = state.copy()[state.week >= test_start_week][['week', 'yhat']]\n",
    "train_data = train.values\n",
    "test_data = test.values\n",
    "train_data_timesteps=np.array([[j for j in train_data[i:i+timesteps]] for i in range(0,len(train_data)-timesteps+1)])[:,:,1]\n",
    "test_data_timesteps=np.array([[j for j in test_data[i:i+timesteps]] for i in range(0,len(test_data)-timesteps+1)])[:,:,1]\n",
    "\n",
    "x_train, y_train = train_data_timesteps[:,:timesteps-1], train_data_timesteps[:,timesteps-1]\n",
    "x_test, y_test = test_data_timesteps[:,:timesteps-1], test_data_timesteps[:,timesteps-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63af4ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which values to check?\n",
    "gammas_to_check = 5**np.arange(-2.1, 1.9, 1)\n",
    "Cs_to_check = 10**np.arange(6)\n",
    "\n",
    "params = {'regressor__gamma': gammas_to_check,\n",
    "          'regressor__C': Cs_to_check}\n",
    "\n",
    "# Search over parameter space using a gridsearch\n",
    "gridsearch = GridSearchCV(pipe, params, verbose=1).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fc42a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit pipe with optimal hyperparameters\n",
    "pipe = Pipeline([('regressor', SVR(kernel='rbf', gamma=gridsearch.best_params_['regressor__gamma'], \\\n",
    "                                   C = gridsearch.best_params_['regressor__C'], epsilon = 0.05))])\n",
    "pipe.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b756f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_train_pred = pipe.predict(x_train).reshape(-1,1)\n",
    "y_test_pred = pipe.predict(x_test).reshape(-1,1)\n",
    "\n",
    "# Predict k weeks into the future\n",
    "to_predict = 30\n",
    "\n",
    "predicted_values = np.empty((0, 1))\n",
    "predictors = np.empty((0, 4))\n",
    "predictors = np.vstack([predictors, np.array(x_test[-1,:])])\n",
    "\n",
    "for i in range(to_predict):\n",
    "    predicted_values = np.array([pipe.predict(predictors)])\n",
    "    new_predictors = predictors[i][range(1,4)]\n",
    "    new_predictors = np.concatenate([new_predictors, [predicted_values[0][i]]], axis = 0)\n",
    "    predictors = np.vstack([predictors, new_predictors])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4b14c0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the predicted versus actual values using tuned values\n",
    "\n",
    "# Make it so that the lines connect\n",
    "new = pd.DataFrame({'week': [test.iloc[0, 0]], 'yhat': [test.iloc[0, 1]]})\n",
    "train = pd.concat([train, new])\n",
    "\n",
    "weeks_training = state.loc[state['week'] <= test_start_week, 'week']\n",
    "weeks_testing  = state.loc[state['week'] >= test_start_week, 'week']\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=train['week'], y=train['yhat'], name=\"Training data\", connectgaps=True))\n",
    "fig.add_trace(go.Scatter(x=test['week'], y=test['yhat'], name=\"Test data\", connectgaps=True))\n",
    "fig.add_trace(go.Scatter(x=np.arange(test_start_week + timesteps, 117 + to_predict), \\\n",
    "                         y=np.concatenate([y_test_pred.flatten(), predicted_values[0][range(1,to_predict)]]), \\\n",
    "                         name=\"Predicted data\", connectgaps=True))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6156770",
   "metadata": {},
   "source": [
    "## What would have happened if vaccinations didn't exist?\n",
    "\n",
    "In this section, we train an svm on the data before vaccinations were made available for all people at risk. Next, we can predict the infection rates for the whole period and compare these predictions with the actual data. The hope is that in this way we can see the effect of vaccinations on the infection rates.\n",
    "\n",
    "The reality is that the predicted curves match almost exactly the true curves and hence that Vaccination does not influence the infection number at all. The predictions are so perfect that I suspect there is something wrong with this code, but I cannot figure out what."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2c37c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in state data\n",
    "agg_week_state = pd.read_csv(\"PreprocessedData/agg_week_state.csv\", index_col = False)\n",
    "\n",
    "# Select a state\n",
    "selected_state = 6\n",
    "\n",
    "state = agg_week_state.loc[agg_week_state['state'] == selected_state]\n",
    "\n",
    "# Load in measure data\n",
    "measures = pd.read_csv(\"PreprocessedData/measures.csv\")\n",
    "\n",
    "# Preprocess the vaccination data\n",
    "state_measures = measures.loc[measures['fips'] == selected_state, ['week', 'Vaccination']]\n",
    "state_measures = state_measures.loc[state_measures['Vaccination'].shift() != state_measures['Vaccination']]\n",
    "state_measures.reset_index(inplace = True, drop = True)\n",
    "state_measures = state_measures.loc[1:,]\n",
    "state_measures.reset_index(inplace = True, drop = True)\n",
    "\n",
    "# Define the pipeline. Note that this pipeline does not include the information about the lag\n",
    "pipe = Pipeline([('regressor', SVR(kernel='rbf', gamma=0.5, C = 10, epsilon = 0.05))])\n",
    "\n",
    "# Get the week from which point onwards vaccinations became available\n",
    "test_start_week = state_measures.loc[state_measures['Vaccination'] == 1].iloc[0, 0]\n",
    "\n",
    "# Still use lag = 4\n",
    "timesteps = 15\n",
    "\n",
    "state['yhat'] = savgol_filter(state['r'], 21, 3)\n",
    "\n",
    "train = state.copy()[state.week < test_start_week][['week', 'yhat']]\n",
    "test = state.copy()[state.week >= test_start_week][['week', 'yhat']]\n",
    "train_data = train.values\n",
    "test_data = test.values\n",
    "train_data_timesteps=np.array([[j for j in train_data[i:i+timesteps]] for i in range(0,len(train_data)-timesteps+1)])[:,:,1]\n",
    "test_data_timesteps=np.array([[j for j in test_data[i:i+timesteps]] for i in range(0,len(test_data)-timesteps+1)])[:,:,1]\n",
    "\n",
    "x_train, y_train = train_data_timesteps[:,:timesteps-1], train_data_timesteps[:,timesteps-1]\n",
    "x_test, y_test = test_data_timesteps[:,:timesteps-1], test_data_timesteps[:,timesteps-1]\n",
    "\n",
    "# Which values to check?\n",
    "gammas_to_check = 5**np.arange(-2.1, 1.9, 1)\n",
    "Cs_to_check = 10**np.arange(6)\n",
    "\n",
    "params = {'regressor__gamma': gammas_to_check,\n",
    "          'regressor__C': Cs_to_check}\n",
    "\n",
    "# Search over parameter space using a gridsearch\n",
    "gridsearch = GridSearchCV(pipe, params, verbose=0).fit(x_train, y_train)\n",
    "print(gridsearch.best_params_)\n",
    "\n",
    "# Predict the remaining weeks\n",
    "to_predict = 116 - test_start_week\n",
    "\n",
    "predicted_values = np.empty((0, 1))\n",
    "predictors = np.empty((0, timesteps - 1))\n",
    "predictors = np.vstack([predictors, np.array(x_train[-1,:])])\n",
    "\n",
    "for i in range(to_predict):\n",
    "    predicted_values = np.array([gridsearch.predict(predictors)])\n",
    "    new_predictors = predictors[i][range(1,timesteps-1)]\n",
    "    new_predictors = np.concatenate([new_predictors, [predicted_values[0][i]]], axis = 0)\n",
    "    predictors = np.vstack([predictors, new_predictors])\n",
    "\n",
    "# Plot the predicted versus actual values using tuned values\n",
    "\n",
    "# Make it so that the lines connect\n",
    "predicted_values = np.insert(predicted_values, 0, train.iloc[-1, 1])\n",
    "\n",
    "new = pd.DataFrame({'week': [train.iloc[-1, 0]], 'yhat': [train.iloc[-1, 1]]})\n",
    "test = pd.concat([new, test])\n",
    "\n",
    "weeks_training = state.loc[state['week'] <= test_start_week, 'week']\n",
    "weeks_testing  = state.loc[state['week'] >= test_start_week, 'week']\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=train['week'], y=train['yhat'], name=\"Training data\", connectgaps=True))\n",
    "fig.add_trace(go.Scatter(x=test['week'], y=test['yhat'], name=\"Test data\", connectgaps=True))\n",
    "fig.add_trace(go.Scatter(x=np.arange(test_start_week - 1, 116 ), \\\n",
    "                         y=predicted_values[range(0,to_predict)], \\\n",
    "                         name=\"Predicted data\", connectgaps=True))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a084615",
   "metadata": {},
   "source": [
    "## What would happen if masks didn't exist?\n",
    "\n",
    "We can do the same for masks. However, since obligatory mask use was introduced very early in many states, there is not enough data to train the model on. On the other hand, the fact that the program throws this warning/error does reasure us that the code correct, and hence the result from the previous section are correct. \n",
    "\n",
    "Note: the code below is outdated, but since we are not using this I didn't bother updating it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81bda4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in state data\n",
    "agg_week_state = pd.read_csv(\"PreprocessedData/agg_week_state.csv\", index_col = False)\n",
    "\n",
    "# Select a state\n",
    "selected_state = 40\n",
    "\n",
    "state = agg_week_state.loc[agg_week_state['state'] == selected_state]\n",
    "\n",
    "# Load in measure data\n",
    "measures = pd.read_csv(\"PreprocessedData/measures.csv\")\n",
    "\n",
    "# Preprocess the vaccination data\n",
    "state_measures = measures.loc[measures['fips'] == selected_state, ['week', 'Masks']]\n",
    "state_measures = state_measures.loc[state_measures['Masks'].shift() != state_measures['Masks']]\n",
    "state_measures.reset_index(inplace = True, drop = True)\n",
    "state_measures = state_measures.loc[1:,]\n",
    "state_measures.reset_index(inplace = True, drop = True)\n",
    "\n",
    "# Define the pipeline. Note that this pipeline does not include the information about the lag\n",
    "pipe = Pipeline([('regressor', SVR(kernel='rbf', gamma=0.5, C = 10, epsilon = 0.05))])\n",
    "\n",
    "# Get the week from which point onwards vaccinations became available\n",
    "test_start_week = state_measures.loc[state_measures['Masks'] == 1].iloc[0, 0]\n",
    "\n",
    "# Still use lag = 4\n",
    "timesteps=5\n",
    "\n",
    "if state['r'].shape[0] > 21:\n",
    "    state['yhat'] = savgol_filter(state['r'], 21, 3)\n",
    "\n",
    "train = state.copy()[state.week < test_start_week][['week', 'yhat']]\n",
    "test = state.copy()[state.week >= test_start_week][['week', 'yhat']]\n",
    "train_data = train.values\n",
    "test_data = test.values\n",
    "train_data_timesteps=np.array([[j for j in train_data[i:i+timesteps]] for i in range(0,len(train_data)-timesteps+1)])[:,:,1]\n",
    "test_data_timesteps=np.array([[j for j in test_data[i:i+timesteps]] for i in range(0,len(test_data)-timesteps+1)])[:,:,1]\n",
    "\n",
    "x_train, y_train = train_data_timesteps[:,:timesteps-1], train_data_timesteps[:,timesteps-1]\n",
    "x_test, y_test = test_data_timesteps[:,:timesteps-1], test_data_timesteps[:,timesteps-1]\n",
    "\n",
    "# Which values to check?\n",
    "gammas_to_check = 5**np.arange(-2.1, 1.9, 1)\n",
    "Cs_to_check = 10**np.arange(6)\n",
    "\n",
    "params = {'regressor__gamma': gammas_to_check,\n",
    "          'regressor__C': Cs_to_check}\n",
    "\n",
    "# Search over parameter space using a gridsearch\n",
    "gridsearch = GridSearchCV(pipe, params, verbose=0).fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_test_pred = gridsearch.predict(x_test).reshape(-1,1)\n",
    "\n",
    "# Predict k weeks into the future\n",
    "to_predict = 30\n",
    "\n",
    "predicted_values = np.empty((0, 1))\n",
    "predictors = np.empty((0, 4))\n",
    "predictors = np.vstack([predictors, np.array(x_test[-1,:])])\n",
    "\n",
    "for i in range(to_predict):\n",
    "    predicted_values = np.array([gridsearch.predict(predictors)])\n",
    "    new_predictors = predictors[i][range(1,4)]\n",
    "    new_predictors = np.concatenate([new_predictors, [predicted_values[0][i]]], axis = 0)\n",
    "    predictors = np.vstack([predictors, new_predictors])\n",
    "\n",
    "# Plot the predicted versus actual values using tuned values\n",
    "\n",
    "# Make it so that the lines connect\n",
    "new = pd.DataFrame({'week': [test.iloc[0, 0]], 'yhat': [test.iloc[0, 1]]})\n",
    "train = pd.concat([train, new])\n",
    "\n",
    "weeks_training = state.loc[state['week'] <= test_start_week, 'week']\n",
    "weeks_testing  = state.loc[state['week'] >= test_start_week, 'week']\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=train['week'], y=train['yhat'], name=\"Training data\", connectgaps=True))\n",
    "fig.add_trace(go.Scatter(x=test['week'], y=test['yhat'], name=\"Test data\", connectgaps=True))\n",
    "fig.add_trace(go.Scatter(x=np.arange(test_start_week + timesteps - 1, 116 + to_predict), \\\n",
    "                         y=np.concatenate([y_test_pred.flatten(), predicted_values[0][range(1,to_predict)]]), \\\n",
    "                         name=\"Predicted data\", connectgaps=True))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42782d08",
   "metadata": {},
   "source": [
    "## What would happen if schools never closed?\n",
    "\n",
    "Schools were closed almost instantly so this doesn't work\n",
    "\n",
    "Note: the code below is outdated, but since we are not using this I didn't bother updating it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e2e5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in state data\n",
    "agg_week_state = pd.read_csv(\"PreprocessedData/agg_week_state.csv\", index_col = False)\n",
    "\n",
    "# Select a state\n",
    "selected_state = 6\n",
    "\n",
    "state = agg_week_state.loc[agg_week_state['state'] == selected_state]\n",
    "\n",
    "# Load in measure data\n",
    "measures = pd.read_csv(\"PreprocessedData/measures.csv\")\n",
    "\n",
    "# Preprocess the vaccination data\n",
    "state_measures = measures.loc[measures['fips'] == selected_state, ['week', 'Close_schools']]\n",
    "state_measures = state_measures.loc[state_measures['Close_schools'].shift() != state_measures['Close_schools']]\n",
    "state_measures.reset_index(inplace = True, drop = True)\n",
    "state_measures = state_measures.loc[1:,]\n",
    "state_measures.reset_index(inplace = True, drop = True)\n",
    "\n",
    "# Define the pipeline. Note that this pipeline does not include the information about the lag\n",
    "pipe = Pipeline([('regressor', SVR(kernel='rbf', gamma=0.5, C = 10, epsilon = 0.05))])\n",
    "\n",
    "# Get the week from which point onwards vaccinations became available\n",
    "test_start_week = state_measures.loc[state_measures['Close_schools'] == 1].iloc[0, 0]\n",
    "\n",
    "# Still use lag = 4\n",
    "timesteps=5\n",
    "\n",
    "if state['r'].shape[0] > 21:\n",
    "    state['yhat'] = savgol_filter(state['r'], 21, 3)\n",
    "\n",
    "train = state.copy()[state.week < test_start_week][['week', 'yhat']]\n",
    "test = state.copy()[state.week >= test_start_week][['week', 'yhat']]\n",
    "train_data = train.values\n",
    "test_data = test.values\n",
    "train_data_timesteps=np.array([[j for j in train_data[i:i+timesteps]] for i in range(0,len(train_data)-timesteps+1)])[:,:,1]\n",
    "test_data_timesteps=np.array([[j for j in test_data[i:i+timesteps]] for i in range(0,len(test_data)-timesteps+1)])[:,:,1]\n",
    "\n",
    "x_train, y_train = train_data_timesteps[:,:timesteps-1], train_data_timesteps[:,timesteps-1]\n",
    "x_test, y_test = test_data_timesteps[:,:timesteps-1], test_data_timesteps[:,timesteps-1]\n",
    "\n",
    "# Which values to check?\n",
    "gammas_to_check = 5**np.arange(-2.1, 1.9, 1)\n",
    "Cs_to_check = 10**np.arange(6)\n",
    "\n",
    "params = {'regressor__gamma': gammas_to_check,\n",
    "          'regressor__C': Cs_to_check}\n",
    "\n",
    "# Search over parameter space using a gridsearch\n",
    "gridsearch = GridSearchCV(pipe, params, verbose=0).fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_test_pred = gridsearch.predict(x_test).reshape(-1,1)\n",
    "\n",
    "# Predict k weeks into the future\n",
    "to_predict = 30\n",
    "\n",
    "predicted_values = np.empty((0, 1))\n",
    "predictors = np.empty((0, 4))\n",
    "predictors = np.vstack([predictors, np.array(x_test[-1,:])])\n",
    "\n",
    "for i in range(to_predict):\n",
    "    predicted_values = np.array([gridsearch.predict(predictors)])\n",
    "    new_predictors = predictors[i][range(1,4)]\n",
    "    new_predictors = np.concatenate([new_predictors, [predicted_values[0][i]]], axis = 0)\n",
    "    predictors = np.vstack([predictors, new_predictors])\n",
    "\n",
    "# Plot the predicted versus actual values using tuned values\n",
    "\n",
    "# Make it so that the lines connect\n",
    "new = pd.DataFrame({'week': [test.iloc[0, 0]], 'yhat': [test.iloc[0, 1]]})\n",
    "train = pd.concat([train, new])\n",
    "\n",
    "weeks_training = state.loc[state['week'] <= test_start_week, 'week']\n",
    "weeks_testing  = state.loc[state['week'] >= test_start_week, 'week']\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=train['week'], y=train['yhat'], name=\"Training data\", connectgaps=True))\n",
    "fig.add_trace(go.Scatter(x=test['week'], y=test['yhat'], name=\"Test data\", connectgaps=True))\n",
    "fig.add_trace(go.Scatter(x=np.arange(test_start_week + timesteps - 1, 116 + to_predict), \\\n",
    "                         y=np.concatenate([y_test_pred.flatten(), predicted_values[0][range(1,to_predict)]]), \\\n",
    "                         name=\"Predicted data\", connectgaps=True))\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
